
@book{siegwart_introduction_2011,
	address = {Cambridge, Massachusetts London, England},
	edition = {Second},
	series = {Intelligent robotics and autonomous agents},
	title = {Introduction to autonomous mobile robots},
	isbn = {978-0-262-01535-6},
	language = {eng},
	urldate = {2024-04-08},
	publisher = {MIT Press},
	author = {Siegwart, Roland and Nourbakhsh, Illah Reza and Scaramuzza, Davide},
	year = {2011},
	keywords = {SLAM},
	file = {Table of Contents PDF:C\:\\Users\\Mikael\\Zotero\\storage\\RRTFULU2\\Siegwart et al. - 2011 - Introduction to autonomous mobile robots.pdf:application/pdf},
}

@inproceedings{kondo_localizability_2022,
	title = {Localizability {Estimation} based on {Occupancy} {Grid} {Maps}},
	url = {https://ieeexplore.ieee.org/document/9863325},
	doi = {10.1109/AIM52237.2022.9863325},
	abstract = {Simultaneous localization and mapping (SLAM) is a widely used technique in autonomous mobile robots. This study deals with the estimation of localizability, which indicates the reliability of localization at each location on the occupancy grid maps created by SLAM. There are several approaches to estimate localizability, this paper proposes a method using local map correlation. Our method represents the localizability using a covariance matrix of a Gaussian distribution, not just a scalar value. The simulation experiment results showed that the uncertainty of localizability increased at locations where degeneration is likely to occur, suggesting that localizability could be estimated appropriately.},
	urldate = {2024-04-10},
	booktitle = {2022 {IEEE}/{ASME} {International} {Conference} on {Advanced} {Intelligent} {Mechatronics} ({AIM})},
	author = {Kondo, Maiku and Hoshi, Masahiko and Hara, Yoshitaka and Nakamura, Sousuke},
	month = jul,
	year = {2022},
	note = {ISSN: 2159-6255},
	keywords = {Computational modeling, Correlation, Estimation, Location awareness, Mechatronics, Simultaneous localization and mapping, Uncertainty},
	pages = {368--373},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\HMUB8Z8N\\Kondo et al. - 2022 - Localizability Estimation based on Occupancy Grid .pdf:application/pdf},
}

@article{macenski_slam_2021,
	title = {{SLAM} {Toolbox}: {SLAM} for the dynamic world},
	volume = {6},
	issn = {2475-9066},
	shorttitle = {{SLAM} {Toolbox}},
	url = {https://joss.theoj.org/papers/10.21105/joss.02783},
	doi = {10.21105/joss.02783},
	abstract = {Macenski et al., (2021). SLAM Toolbox: SLAM for the dynamic world. Journal of Open Source Software, 6(61), 2783, https://doi.org/10.21105/joss.02783},
	language = {en},
	number = {61},
	urldate = {2024-04-10},
	journal = {Journal of Open Source Software},
	author = {Macenski, Steve and Jambrecic, Ivona},
	month = may,
	year = {2021},
	pages = {2783},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\ZHQ6VYLI\\Macenski and Jambrecic - 2021 - SLAM Toolbox SLAM for the dynamic world.pdf:application/pdf},
}

@inproceedings{andriawan_eka_wijaya_research_2019,
	title = {Research {Study} of {Occupancy} {Grid} map {Mapping} {Method} on {Hector} {SLAM} {Technique}},
	url = {https://ieeexplore.ieee.org/document/8901657},
	doi = {10.1109/ELECSYM.2019.8901657},
	abstract = {This research focuses on mapping at indoor environment where differential drive mobile robots are used as a vehicle. The unknown environment to robots is a problem in robotics, therefore the grid map occupancy method was used as mapping method in unknown environment, so that robots can represent the results of environmental mapping using LIDAR sensors to a 2D map. The experiment done by the mobile robot was equipped with a LIDAR sensor as a sensor for retrieving data around the robot where the robot was instructed to explore the corridor inside a building and do mapping in real time. After experiment done, this method successfully mapped the environment around the robot with an average mapping error 6.05 cm.},
	urldate = {2024-04-11},
	booktitle = {2019 {International} {Electronics} {Symposium} ({IES})},
	author = {Andriawan Eka Wijaya, Syahrul Fajar and Setyo Purnomo, Didik and Utomo, Eko Budi and Akbaryan Anandito, Muhammad},
	month = sep,
	year = {2019},
	keywords = {2D Mapping, Hector SLAM, LIDAR Sensor, Mobile Robot, Occupancy Grid map},
	pages = {238--241},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\GBAZR75K\\Andriawan Eka Wijaya et al. - 2019 - Research Study of Occupancy Grid map Mapping Metho.pdf:application/pdf},
}

@inproceedings{zhao_occupancy-slam_2022,
	title = {Occupancy-{SLAM}: {Simultaneously} {Optimizing} {Robot} {Poses} and {Continuous} {Occupancy} {Map}},
	isbn = {978-0-9923747-8-5},
	shorttitle = {Occupancy-{SLAM}},
	url = {http://www.roboticsproceedings.org/rss18/p003.pdf},
	doi = {10.15607/RSS.2022.XVIII.003},
	abstract = {In this paper, we propose an optimization based SLAM approach to simultaneously optimize the robot trajectory and the occupancy map using 2D laser scans (and odometry) information. The key novelty is that the robot poses and the occupancy map are optimized together, which is significantly different from existing occupancy mapping strategies where the robot poses need to be obtained first before the map can be estimated. In our formulation, the map is represented as a continuous occupancy map where each 2D point in the environment has a corresponding evidence value. The Occupancy-SLAM problem is formulated as an optimization problem where the variables include all the robot poses and the occupancy values at the selected discrete grid cell nodes. We propose a variation of Gauss-Newton method to solve this new formulated problem, obtaining the optimized occupancy map and robot trajectory together with their uncertainties. Our algorithm is an offline approach since it is based on batch optimization and the number of variables involved is large. Evaluations using simulations and publicly available practical 2D laser datasets demonstrate that the proposed approach can estimate the maps and robot trajectories more accurately than the state-of-the-art techniques, when a relatively accurate initial guess is provided to our algorithm. The video shows the convergence process of the proposed OccupancySLAM and comparison of results to Cartographer can be found at https://youtu.be/4oLyVEUC4iY.},
	language = {en},
	urldate = {2024-04-11},
	booktitle = {Robotics: {Science} and {Systems} {XVIII}},
	publisher = {Robotics: Science and Systems Foundation},
	author = {Zhao, Liang and Wang, Yingyu and Huang, Shoudong},
	month = jun,
	year = {2022},
	file = {Zhao et al. - 2022 - Occupancy-SLAM Simultaneously Optimizing Robot Po.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\2JDPKADK\\Zhao et al. - 2022 - Occupancy-SLAM Simultaneously Optimizing Robot Po.pdf:application/pdf},
}

@article{mu_occupancy_2022,
	title = {Occupancy {Grid}-{Based} {AUV} {SLAM} {Method} with {Forward}-{Looking} {Sonar}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/10/8/1056},
	doi = {10.3390/jmse10081056},
	abstract = {Simultaneous localization and mapping (SLAM) is an active localization method for Autonomous Underwater Vehicle (AUV), and it can mainly be used in unknown and complex areas such as coastal water, harbors, and wharfs. This paper presents a practical occupancy grid-based method based on forward-looking sonar for AUV. The algorithm uses an extended Kalman filter (EKF) to estimate the AUV motion states. First, the SLAM method fuses the data coming from the navigation sensors to predict the motion states. Subsequently, a novel particle swarm optimization genetic algorithm (PSO-GA) scan matching method is employed for matching the sonar scan data and grid map, and the matching pose would be used to correct the prediction states. Lastly, the estimated motion states and sonar scan data would be used to update the grid map. The experimental results based on the field data have validated that the proposed SLAM algorithm is adaptable to underwater conditions, and accurate enough to use for ocean engineering practical applications.},
	language = {en},
	number = {8},
	urldate = {2024-04-11},
	journal = {Journal of Marine Science and Engineering},
	author = {Mu, Xiaokai and Yue, Guan and Zhou, Nan and Chen, Congcong},
	month = aug,
	year = {2022},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {SLAM, AUV, grid map, scan matching},
	pages = {1056},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\KZAH74NC\\Mu et al. - 2022 - Occupancy Grid-Based AUV SLAM Method with Forward-.pdf:application/pdf},
}

@inproceedings{schulz_real-time_2020,
	address = {Paris, France},
	title = {Real-{Time} {Graph}-{Based} {SLAM} with {Occupancy} {Normal} {Distributions} {Transforms}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72817-395-5},
	url = {https://ieeexplore.ieee.org/document/9197325/},
	doi = {10.1109/ICRA40945.2020.9197325},
	language = {en},
	urldate = {2024-04-11},
	booktitle = {2020 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Schulz, Cornelia and Zell, Andreas},
	month = may,
	year = {2020},
	pages = {3106--3111},
	file = {Schulz and Zell - 2020 - Real-Time Graph-Based SLAM with Occupancy Normal D.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\634HTIRM\\Schulz and Zell - 2020 - Real-Time Graph-Based SLAM with Occupancy Normal D.pdf:application/pdf},
}

@book{corke_robotics_2023,
	address = {Cham},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Robotics, {Vision} and {Control}: {Fundamental} {Algorithms} in {MATLAB}®},
	volume = {147},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-07261-1 978-3-031-07262-8},
	shorttitle = {Robotics, {Vision} and {Control}},
	url = {https://link.springer.com/10.1007/978-3-031-07262-8},
	language = {en},
	urldate = {2024-04-11},
	publisher = {Springer International Publishing},
	author = {Corke, Peter and Jachimczyk, Witold and Pillat, Remo},
	year = {2023},
	doi = {10.1007/978-3-031-07262-8},
}

@article{cai_lidarinertial_2023,
	title = {A {LiDAR}–{Inertial} {SLAM} {Method} {Based} on {Virtual} {Inertial} {Navigation} {System}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/12/2639},
	doi = {10.3390/electronics12122639},
	abstract = {In scenarios with insufficient structural features, LiDAR-based SLAM may suffer from degeneracy, resulting in impaired robot localization and mapping and potentially leading to subsequent deviant navigation tasks. Therefore, it is crucial to develop advanced algorithms and techniques to mitigate the degeneracy issue and ensure the robustness and accuracy of LiDAR-based SLAM. This paper presents a LiDAR–inertial simultaneous localization and mapping (SLAM) method based on a virtual inertial navigation system (VINS) to address the issue of degeneracy. We classified different gaits and match each gait to its corresponding torso inertial measurement unit (IMU) sensor to construct virtual foot inertial navigation components. By combining an inertial navigation system (INS) with zero-velocity updates (ZUPTs), we formed the VINS to achieve real-time estimation and correction. Finally, the corrected pose estimation was input to the IMU odometry calculation procedure to further refine the localization and mapping results. To evaluate the effectiveness of our proposed VINS method in degenerate environments, we conducted experiments in three typical scenarios. The results demonstrate the high suitability and accuracy of the proposed method in degenerate scenes and show an improvement in the point clouds mapping effect. The algorithm’s versatility is emphasized by its wide applicability on GPU platforms, including quadruped robots and human wearable devices. This broader potential range of applications extends to other related fields such as autonomous driving.},
	language = {en},
	number = {12},
	urldate = {2024-04-22},
	journal = {Electronics},
	author = {Cai, Yunpiao and Qian, Weixing and Dong, Jiayi and Zhao, Jiaqi and Wang, Kerui and Shen, Tianxiao},
	month = jan,
	year = {2023},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {attention-based convolutional, LiDAR–inertial navigation, neural network, ResNet-gated recurrent unit neural network, simultaneous mapping and localization technology, virtual IMU construction},
	pages = {2639},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\7QWUF7PC\\Cai et al. - 2023 - A LiDAR–Inertial SLAM Method Based on Virtual Iner.pdf:application/pdf},
}

@article{filip_lidar_2023,
	title = {{LiDAR} {SLAM} with a {Wheel} {Encoder} in a {Featureless} {Tunnel} {Environment}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/4/1002},
	doi = {10.3390/electronics12041002},
	abstract = {Simultaneous localization and mapping (SLAM) represents a crucial algorithm in the autonomous navigation of ground vehicles. Several studies were conducted to improve the SLAM algorithm using various sensors and robot platforms. However, only a few works have focused on applications inside low-illuminated featureless tunnel environments. In this work, we present an improved SLAM algorithm using wheel encoder data from an autonomous ground vehicle (AGV) to obtain robust performance in a featureless tunnel environment. The improved SLAM system uses FAST-LIO2 LiDAR SLAM as the baseline algorithm, and the additional wheel encoder sensor data are integrated into the baseline SLAM structure using the extended Kalman filter (EKF) algorithm. The EKF algorithm is used after the LiDAR odometry estimation and before the mapping process of FAST-LIO2. The prediction step uses the wheel encoder and inertial measurement unit (IMU) data, while the correction step uses the FAST-LIO2 LiDAR state estimation. We used an AGV to conduct experiments in flat and inclined terrain sections in a tunnel environment. The results showed that the mapping and the localization process in the SLAM algorithm was greatly improved in a featureless tunnel environment considering both inclined and flat terrains.},
	language = {en},
	number = {4},
	urldate = {2024-04-22},
	journal = {Electronics},
	author = {Filip, Iulian and Pyo, Juhyun and Lee, Meungsuk and Joe, Hangil},
	month = jan,
	year = {2023},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {LiDAR SLAM, tunnel, wheel encoder},
	pages = {1002},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\9CXC4HZV\\Filip et al. - 2023 - LiDAR SLAM with a Wheel Encoder in a Featureless T.pdf:application/pdf},
}

@article{fasiolo_comparing_2023,
	title = {Comparing {LiDAR} and {IMU}-based {SLAM} approaches for {3D} robotic mapping},
	volume = {41},
	issn = {0263-5747, 1469-8668},
	url = {https://www.cambridge.org/core/journals/robotica/article/comparing-lidar-and-imubased-slam-approaches-for-3d-robotic-mapping/D5B49F3F7FC0992EE0CA3A6DD85BAAB8},
	doi = {10.1017/S026357472300053X},
	abstract = {In this paper, we propose a comparison of open-source LiDAR and Inertial Measurement Unit (IMU)-based Simultaneous Localization and Mapping (SLAM) approaches for 3D robotic mapping. The analyzed algorithms are often exploited in mobile robotics for autonomous navigation but have not been evaluated in terms of 3D reconstruction yet. Experimental tests are carried out using two different autonomous mobile platforms in three test cases, comprising both indoor and outdoor scenarios. The 3D models obtained with the different SLAM algorithms are then compared in terms of density, accuracy, and noise of the point clouds to analyze the performance of the evaluated approaches. The experimental results indicate the SLAM methods that are more suitable for 3D mapping in terms of the quality of the reconstruction and highlight the feasibility of mobile robotics in the field of autonomous mapping.},
	language = {en},
	number = {9},
	urldate = {2024-04-23},
	journal = {Robotica},
	author = {Fasiolo, Diego Tiozzo and Scalera, Lorenzo and Maset, Eleonora},
	month = sep,
	year = {2023},
	keywords = {SLAM, 3D reconstruction, IMU, LiDAR, mobile robotics},
	pages = {2588--2604},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\UMDEMZJG\\Fasiolo et al. - 2023 - Comparing LiDAR and IMU-based SLAM approaches for .pdf:application/pdf},
}

@inproceedings{khole_comprehensive_2023,
	title = {A {Comprehensive} {Study} on {Simultaneous} {Localization} and {Mapping} ({SLAM}): {Types}, {Challenges} and {Applications}},
	shorttitle = {A {Comprehensive} {Study} on {Simultaneous} {Localization} and {Mapping} ({SLAM})},
	url = {https://ieeexplore.ieee.org/document/10169695},
	doi = {10.1109/ICSCSS57650.2023.10169695},
	abstract = {Simultaneous Localization and Mapping (SLAM) has emerged as a pivotal research area within the realm of artificial intelligence mobile robots. Its significance lies in the ability to facilitate self-exploration of unknown environments without the aid of human intervention. The unique and distinctive aspect of SLAM is its ability to map and localize the robot’s surroundings recursively and continuously. With the advent of SLAM, numerous algorithms have been proposed to address the challenges encountered in real-world applications of this technique. The main aim of this research is to provide a comprehensive and thorough analysis of the theoretical underpinnings, recent advancements, distinctive features, implementation strategies, and emerging issues in the domain of SLAM. This exploration intends to enhance the understanding and promote the advancement of this critical research area.},
	urldate = {2024-05-01},
	booktitle = {2023 {International} {Conference} on {Sustainable} {Computing} and {Smart} {Systems} ({ICSCSS})},
	author = {Khole, Aneesh and Thakar, Atharva and Shende, Shreyas and Karajkhede, Varad},
	month = jun,
	year = {2023},
	keywords = {Location awareness, Simultaneous localization and mapping, Real-time systems, Visualization, Complexity theory, Deep Learning Visual Odometry, Extended Kalman Filter, Features, Hardware, Local Bundle Adjustment, Localization, Mapping, Mobile robots, Simultaneous Localization and Mapping},
	pages = {643--650},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\SC9GPBU5\\Khole et al. - 2023 - A Comprehensive Study on Simultaneous Localization.pdf:application/pdf},
}

@article{khan_investigation_2022,
	title = {Investigation of {Widely} {Used} {SLAM} {Sensors} {Using} {Analytical} {Hierarchy} {Process}},
	volume = {2022},
	issn = {1687-725X},
	url = {https://www.hindawi.com/journals/js/2022/5428097/},
	doi = {10.1155/2022/5428097},
	abstract = {Applications of mobile robots are continuously capturing the importance in numerous areas such as agriculture, surveillance, defense, and planetary exploration to name a few. Accurate navigation of a mobile robot is highly significant for its uninterrupted operation. Simultaneous localization and mapping (SLAM) is one of the widely used techniques in mobile robots for localization and navigation. SLAM consists of front- and back-end processes, wherein the front-end includes SLAM sensors. These sensors play a significant role in acquiring accurate environmental information for further processing and mapping. Therefore, understanding the operational limits of the available SLAM sensors and data collection techniques from a single sensor or multisensors is noteworthy. In this article, a detailed literature review of widely used SLAM sensors such as acoustic sensor, RADAR, camera, Light Detection and Ranging (LiDAR), and RGB-D is provided. The performance of SLAM sensors is compared using an analytical hierarchy process (AHP) based on various key indicators such as accuracy, range, cost, working environment, and computational cost.},
	language = {en},
	urldate = {2024-05-01},
	journal = {Journal of Sensors},
	author = {Khan, Muhammad Shahzad Alam and Hussain, Danish and Naveed, Kanwal and Khan, Umar S. and Mundial, Imran Qayyum and Aqeel, Anas Bin},
	month = jan,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e5428097},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\NKXU3PXB\\Khan et al. - 2022 - Investigation of Widely Used SLAM Sensors Using An.pdf:application/pdf},
}

@inproceedings{ilas_electronic_2013,
	title = {Electronic sensing technologies for autonomous ground vehicles: {A} review},
	shorttitle = {Electronic sensing technologies for autonomous ground vehicles},
	url = {https://ieeexplore.ieee.org/document/6563528},
	doi = {10.1109/ATEE.2013.6563528},
	abstract = {Autonomous ground vehicles have evolved a lot in the past decade. Several prototypes have been presented and tested in different conditions. A major challenge for such vehicles is the fact that they depend on advanced sensing technologies to perceive the environment and make real-time decisions. The complexity of this task typically requires multiple sensing devices, which is both a technical challenge as well as a limiting factor for autonomous vehicles evolution to mass-production. In this paper we review the current main sensing technologies for autonomous ground vehicles, their suitability and maturity status, as well as the way they have been used in prototype cars. This analysis gives a perspective of their evolution so far, as well as an indication of possible future trends.},
	urldate = {2024-05-01},
	booktitle = {2013 {8TH} {INTERNATIONAL} {SYMPOSIUM} {ON} {ADVANCED} {TOPICS} {IN} {ELECTRICAL} {ENGINEERING} ({ATEE})},
	author = {Ilas, Constantin},
	month = may,
	year = {2013},
	note = {ISSN: 2068-7966},
	keywords = {autonomous ground vehicles, camera, Cameras, Laser radar, LIDAR, Prototypes, radar, Roads, sensing devices, Sensors, Vehicles},
	pages = {1--6},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\4PAYFLPC\\Ilas - 2013 - Electronic sensing technologies for autonomous gro.pdf:application/pdf},
}

@misc{slamtec_rplidar_2016,
	title = {{RPLIDAR} {A1}},
	url = {https://eu.mouser.com/datasheet/2/830/LD108_SLAMTEC_rplidar_datasheet_A1M8_v1_0_en-2487185.pdf},
	language = {en},
	urldate = {2024-05-03},
	publisher = {Shanghai Slamtec.Co.,Ltd},
	author = {Slamtec},
	month = jul,
	year = {2016},
}

@misc{invensense_mpu-6000_2013,
	title = {{MPU}-6000 and {MPU}-6050 {Product} {Specification} {Revision} 3.4},
	url = {https://invensense.tdk.com/wp-content/uploads/2015/02/MPU-6000-Datasheet1.pdf},
	language = {en},
	urldate = {2024-05-03},
	publisher = {InvenSense Inc.},
	author = {InvenSense},
	month = aug,
	year = {2013},
}

@misc{macenski_use_2019,
	address = {ROSCon},
	title = {On {Use} of {SLAM} {Toolbox}, {A} fresh(er) look at mapping and localization for the dynamic world},
	url = {https://vimeo.com/378682207},
	language = {en},
	urldate = {2024-05-03},
	author = {Macenski, Steve},
	year = {2019},
}

@misc{macenski_open-source_2024,
	title = {Open-{Source}, {Cost}-{Aware} {Kinematically} {Feasible} {Planning} for {Mobile} and {Surface} {Robotics}},
	url = {http://arxiv.org/abs/2401.13078},
	abstract = {This paper introduces the Smac Planner, an openly available search-based planning framework with multiple algorithm implementations including 2D-A*, Hybrid-A*, and State Lattice planners. This work is motivated by the lack of performant and available feasible planners for mobile and surface robotics research.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Macenski, Steve and Booker, Matthew and Wallace, Joshua},
	month = jan,
	year = {2024},
	note = {arXiv:2401.13078 [cs]},
	keywords = {Computer Science - Robotics},
	file = {Macenski et al. - 2024 - Open-Source, Cost-Aware Kinematically Feasible Pla.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\AL7AHQ6M\\Macenski et al. - 2024 - Open-Source, Cost-Aware Kinematically Feasible Pla.pdf:application/pdf},
}

@misc{macenski_regulated_2023,
	title = {Regulated {Pure} {Pursuit} for {Robot} {Path} {Tracking}},
	url = {http://arxiv.org/abs/2305.20026},
	abstract = {The accelerated deployment of service robots have spawned a number of algorithm variations to better handle real-world conditions. Many local trajectory planning techniques have been deployed on practical robot systems successfully. While most formulations of Dynamic Window Approach and Model Predictive Control can progress along paths and optimize for additional criteria, the use of pure path tracking algorithms is still commonplace. Decades later, Pure Pursuit and its variants continues to be one of the most commonly utilized classes of local trajectory planners. However, few Pure Pursuit variants have been proposed with schema for variable linear velocities - they either assume a constant velocity or fails to address the point at all. This paper presents a variant of Pure Pursuit designed with additional heuristics to regulate linear velocities, built atop the existing Adaptive variant. The Regulated Pure Pursuit algorithm makes incremental improvements on state of the art by adjusting linear velocities with particular focus on safety in constrained and partially observable spaces commonly negotiated by deployed robots. We present experiments with the Regulated Pure Pursuit algorithm on industrial-grade service robots. We also provide a high-quality reference implementation that is freely included ROS 2 Nav2 framework at https://github.com/ros-planning/navigation2 for fast evaluation.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Macenski, Steve and Singh, Shrijit and Martin, Francisco and Gines, Jonatan},
	month = may,
	year = {2023},
	note = {arXiv:2305.20026 [cs]},
	keywords = {Computer Science - Robotics},
	file = {Macenski et al. - 2023 - Regulated Pure Pursuit for Robot Path Tracking.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\9EIP45BJ\\Macenski et al. - 2023 - Regulated Pure Pursuit for Robot Path Tracking.pdf:application/pdf},
}

@misc{merzlyakov_comparison_2021,
	title = {A {Comparison} of {Modern} {General}-{Purpose} {Visual} {SLAM} {Approaches}},
	url = {http://arxiv.org/abs/2107.07589},
	abstract = {Advancing maturity in mobile and legged robotics technologies is changing the landscapes where robots are being deployed and found. This innovation calls for a transformation in simultaneous localization and mapping (SLAM) systems to support this new generation of service and consumer robots. No longer can traditionally robust 2D lidar systems dominate while robots are being deployed in multi-story indoor, outdoor unstructured, and urban domains with increasingly inexpensive stereo and RGB-D cameras. Visual SLAM (VSLAM) systems have been a topic of study for decades and a small number of openly available implementations have stood out: ORB-SLAM3, OpenVSLAM and RTABMap.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Merzlyakov, Alexey and Macenski, Steve},
	month = aug,
	year = {2021},
	note = {arXiv:2107.07589 [cs]},
	keywords = {Computer Science - Robotics},
	file = {Merzlyakov and Macenski - 2021 - A Comparison of Modern General-Purpose Visual SLAM.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\F5V86HS7\\Merzlyakov and Macenski - 2021 - A Comparison of Modern General-Purpose Visual SLAM.pdf:application/pdf},
}

@inproceedings{macenski_marathon_2020,
	title = {The {Marathon} 2: {A} {Navigation} {System}},
	shorttitle = {The {Marathon} 2},
	url = {http://arxiv.org/abs/2003.00368},
	doi = {10.1109/IROS45743.2020.9341207},
	abstract = {Developments in mobile robot navigation have enabled robots to operate in warehouses, retail stores, and on sidewalks around pedestrians. Various navigation solutions have been proposed, though few as widely adopted as ROS (Robot Operating System) Navigation. 10 years on, it is still one of the most popular navigation solutions1. Yet, ROS Navigation has failed to keep up with modern trends. We propose the new navigation solution, Navigation2, which builds on the successful legacy of ROS Navigation. Navigation2 uses a behavior tree for navigator task orchestration and employs new methods designed for dynamic environments applicable to a wider variety of modern sensors. It is built on top of ROS2, a secure message passing framework suitable for safety critical applications and program lifecycle management. We present experiments in a campus setting utilizing Navigation2 to operate safely alongside students over a marathon as an extension of the experiment proposed in Eppstein et al. [1]. The Navigation2 system is freely available at https://github.com/ros-planning/navigation2 with a rich community and instructions.},
	language = {en},
	urldate = {2024-05-07},
	booktitle = {2020 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Macenski, Steve and Martín, Francisco and White, Ruffin and Clavero, Jonatan Ginés},
	month = oct,
	year = {2020},
	note = {arXiv:2003.00368 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {2718--2725},
	file = {Macenski et al. - 2020 - The Marathon 2 A Navigation System.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\DVQMWZQM\\Macenski et al. - 2020 - The Marathon 2 A Navigation System.pdf:application/pdf},
}

@article{macenski_desks_2023,
	title = {From the {Desks} of {ROS} {Maintainers}: {A} {Survey} of {Modern} \& {Capable} {Mobile} {Robotics} {Algorithms} in the {Robot} {Operating} {System} 2},
	volume = {168},
	issn = {09218890},
	shorttitle = {From the {Desks} of {ROS} {Maintainers}},
	url = {http://arxiv.org/abs/2307.15236},
	doi = {10.1016/j.robot.2023.104493},
	abstract = {The Robot Operating System 2 (ROS 2) is rapidly impacting the intelligent machines sector - on space missions, large agriculture equipment, multi-robot fleets, and more. Its success derives from its focused design and improved capabilities targeting product-grade and modern robotic systems. Following ROS 2’s example, the mobile robotics ecosystem has been fully redesigned based on the transformed needs of modern robots and is experiencing active development not seen since its inception.},
	language = {en},
	urldate = {2024-05-07},
	journal = {Robotics and Autonomous Systems},
	author = {Macenski, Steve and Moore, Tom and Lu, David and Merzlyakov, Alexey and Ferguson, Michael},
	month = oct,
	year = {2023},
	note = {arXiv:2307.15236 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {104493},
	file = {Macenski et al. - 2023 - From the Desks of ROS Maintainers A Survey of Mod.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\XSLHLYZT\\Macenski et al. - 2023 - From the Desks of ROS Maintainers A Survey of Mod.pdf:application/pdf},
}

@book{bolton_mechatronics_2019,
	address = {Harlow, England ; New York},
	edition = {Seventh},
	title = {Mechatronics: electronic control systems in mechanical and electrical engineering},
	isbn = {978-1-292-25097-7},
	shorttitle = {Mechatronics},
	abstract = {"The integration of electronic engineering, mechanical engineering, control and computer engineering - Mechatronics - lies at the heart of the innumerable gadgets, processes and technology that makes modern life would seem impossible. From auto-focus cameras to car engine management systems, and from state-of-the-art robots to the humble washing machine, Mechatronics has a hand in them all. This book presents a clear and comprehensive introduction to the area. Practical and applied, it helps you to acquire the mix of skills you will need to comprehend and design mechatronic systems. It also goes much deeper, explaining the very philosophy of mechatronics, and, in so doing, provides you with a frame of understanding to develop a truly interdisciplinary and integrated approach to engineering. This 7th edition has been updated throughout with new sections and examples throughout: - Updated coverage of mechatronic system components, including extended coverage of encoders, position sensitive detectors and force sensitive resistors - New material on Atmega microcontrollers including applications and programming examples - Topical discussion and examples of fuzzy logic and neural control systems Applications and case studies have been revised across the book, with fascinating examples including automated guided vehicles, artificial hands, fuzzy logic washing machines, to help you to gain a modern and practical understanding Mechatronics is essential reading for students requiring an introduction to this exciting area at undergraduate and higher diploma level"--},
	publisher = {Pearson Education Limited},
	author = {Bolton, W.},
	year = {2019},
	keywords = {Mechatronics},
}

@book{storey_electronics_2017,
	address = {Harlow, England London New York Boston San Francisco Toronto},
	edition = {Sixth},
	title = {Electronics: a systems approach},
	isbn = {978-1-292-11406-4},
	shorttitle = {Electronics},
	language = {eng},
	publisher = {Pearson},
	author = {Storey, Neil},
	year = {2017},
}

@book{morris_measurement_2016,
	address = {Amsterdam ; Boston},
	edition = {Second},
	title = {Measurement and instrumentation: theory and application},
	isbn = {978-0-12-800884-3},
	shorttitle = {Measurement and instrumentation},
	publisher = {Elsevier, AP},
	author = {Morris, Alan S. and Langari, Reza},
	year = {2016},
	keywords = {Measurement, Measuring instruments},
}

@article{samatas_inertial_2022,
	title = {Inertial {Measurement} {Units} ({IMUs}) in {Mobile} {Robots} over the {Last} {Five} {Years}: {A} {Review}},
	volume = {6},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2411-9660},
	shorttitle = {Inertial {Measurement} {Units} ({IMUs}) in {Mobile} {Robots} over the {Last} {Five} {Years}},
	url = {https://www.mdpi.com/2411-9660/6/1/17},
	doi = {10.3390/designs6010017},
	abstract = {Robots and especially mobile robots have experienced rapid growth, making them part of everyday life. An inertial measurement unit (IMU), which is a set of sensors, plays an important role in mobile robots’ navigation. Data collected by the IMU sensors on a robot are properly converted and useful information is calculated concerning, i.e., position, orientation, and acceleration. With the advancement of technology, IMUs have been transformed from large and complex devices into small, flexible, and efficient ones. The main sensors included in an IMU are the gyroscope, the accelerometer, and the magnetometer. Additionally, there are other sensors such as a barometer, a temperature sensor, a pressure sensor, or even an attitude sensor. The components that an IMU consists of are many and the main differences concern the technology they integrate, the designer purpose, and the specifications set by the manufacturer. The purpose of this review is a comparative presentation of 42 IMU models from 7 different manufacturers over the last five years comparing main features such as structure details, connectivity, and communication protocols. Moreover, statistical results are quantitatively and qualitatively presented providing a future user the possibility to select the proper IMU.},
	language = {en},
	number = {1},
	urldate = {2024-05-10},
	journal = {Designs},
	author = {Samatas, Gerasimos G. and Pachidis, Theodore P.},
	month = feb,
	year = {2022},
	pages = {17},
	file = {Full Text:C\:\\Users\\Mikael\\Zotero\\storage\\DMI8DJ7X\\Samatas and Pachidis - 2022 - Inertial Measurement Units (IMUs) in Mobile Robots.pdf:application/pdf},
}

@incollection{killinger_lidar_2014,
	title = {Lidar (light detection and ranging)},
	isbn = {978-0-85709-273-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780857092731500106},
	language = {en},
	urldate = {2024-05-10},
	booktitle = {Laser {Spectroscopy} for {Sensing}},
	publisher = {Elsevier},
	author = {Killinger, D.K.},
	year = {2014},
	doi = {10.1533/9780857098733.2.292},
	pages = {292--312},
}

@book{siciliano_robotics_2009,
	address = {London},
	series = {Advanced textbooks in control and signal processing},
	title = {Robotics: modelling, planning and control},
	isbn = {978-1-84628-641-4 978-1-84628-642-1},
	shorttitle = {Robotics},
	publisher = {Springer},
	editor = {Siciliano, Bruno},
	year = {2009},
	note = {OCLC: ocn144222188},
	keywords = {Control systems, Manipulators (Mechanism), Motion, Robots},
}

@article{liu_path_2023,
	title = {Path planning techniques for mobile robots: {Review} and prospect},
	volume = {227},
	issn = {0957-4174},
	shorttitle = {Path planning techniques for mobile robots},
	url = {https://www.sciencedirect.com/science/article/pii/S095741742300756X},
	doi = {10.1016/j.eswa.2023.120254},
	abstract = {Mobile robot path planning refers to the design of the safely collision-free path with shortest distance and least time-consuming from the starting point to the end point by a mobile robot autonomously. In this paper, a systematic review of mobile robot path planning techniques is presented. Firstly, path planning is classified into global path planning and local path planning according to the mastery of environmental information. In the global path planning, environment modeling methods and path evaluation method are introduced. The methods of environment modeling include grid method, topology method, geometric feature method and mixed representation method. In the local path planning, we introduce the sensors commonly used in the detection environment, including laser radar and visual sensor. Next, according to the characteristics of algorithms, mobile robot path planning algorithms are divided into three categories: classical algorithms, bionic algorithms and artificial intelligence algorithms. Among the classical algorithms, we introduce the cell decomposition method, sampling based method, graph search algorithm, artificial potential field method and dynamic window method. In the algorithm based on bionics, we introduce genetic algorithm, ant colony algorithm, gray wolf algorithm, etc. in detail. In artificial intelligence algorithm, we introduce neural network algorithm and fuzzy logic. Finally, we compare the key technologies of mobile robot path planning in the form of graphs and charts based on the classification statistics of the collected literature to provide references for future research.},
	urldate = {2024-05-15},
	journal = {Expert Systems with Applications},
	author = {Liu, Lixing and Wang, Xu and Yang, Xin and Liu, Hongjie and Li, Jianping and Wang, Pengfei},
	month = oct,
	year = {2023},
	keywords = {Mobile robots, Algorithms, Key technologies, Path planning},
	pages = {120254},
	file = {ScienceDirect Snapshot:C\:\\Users\\Mikael\\Zotero\\storage\\T4APV3P5\\S095741742300756X.html:text/html},
}

@article{adzhar_review_2020,
	title = {A {Review} on {Autonomous} {Mobile} {Robot} {Path} {Planning} {Algorithms}},
	volume = {5},
	issn = {24156698, 24156698},
	url = {https://astesj.com/v05/i03/p30/},
	doi = {10.25046/aj050330},
	number = {3},
	urldate = {2024-05-15},
	journal = {Advances in Science, Technology and Engineering Systems Journal},
	author = {Adzhar, Noraziah and Yusof, Yuhani and Ahmad, Muhammad Azrin},
	year = {2020},
	pages = {236--240},
	file = {Full Text:C\:\\Users\\Mikael\\Zotero\\storage\\J4DBSNPD\\Adzhar et al. - 2020 - A Review on Autonomous Mobile Robot Path Planning .pdf:application/pdf},
}

@article{muhammad_path_2020,
	title = {Path planning {Methods} for {Mobile} {Robots}: {A} systematic and {Bibliometric} {Review}},
	volume = {19},
	issn = {0128-4428},
	shorttitle = {Path planning {Methods} for {Mobile} {Robots}},
	url = {https://typeset.io/papers/path-planning-methods-for-mobile-robots-a-systematic-and-59kba9glk1},
	doi = {https://www.doi.org/10.11113/ELEKTRIKA.V19N3.225},
	abstract = {Robots are currently replacing humans in different tasks in various sectors. Among the vital features desirable in autonomous robots is the capability of navigating safely through a given environment. Robot navigation is a process designed with the ability of avoiding any hitches or obstacles while aiming at a specific predefined position. Many studies have been proposed to find solutions to robot path-planning problems. This paper presents a survey of the heuristic and classical path-planning approaches. Focal strengths, together with the weaknesses of these approaches, were also identified to provide deep insight for future studies. As several literature studies have recommended, classical methods might not be effective in real-time applications as a result of their failure to confront the unpredictable nature of the real-world. They require a considerable amount of computation and space, while heuristic-based methods can overcome real-world problems with some modifications. To summarize the research progress and also suggest future directions of path-planning research, this study performs a bibliometric analysis of the relevant publications published from 2000 to 2020. The results show that 5385 articles were published in 1128 journals, hence indicating publication diversity. There is a steady rise in the yearly publication output, reflecting an increase in global research interest in the topic. In general, this research provides useful insight into path-planning research so that researchers in this area can better recognize the relevant research study topics and search for the appropriate research partners.},
	language = {en},
	number = {3},
	urldate = {2024-05-15},
	journal = {Elektrika: Journal of Electrical Engineering},
	author = {Muhammad, Aisha and Ali, Mohammed A. H. and Shanono, Ibrahim Haruna},
	month = dec,
	year = {2020},
	pages = {14--34},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\QSRPKY5C\\2020 - Path planning Methods for Mobile Robots A systema.pdf:application/pdf},
}

@misc{macenski_impact_2023,
	title = {Impact of {ROS} 2 {Node} {Composition} in {Robotic} {Systems}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2305.09933},
	doi = {10.48550/ARXIV.2305.09933},
	abstract = {The Robot Operating System 2 (ROS 2) is the second generation of ROS representing a step forward in the robotic framework. Several new types of nodes and executor models are integral to control where, how, and when information is processed in the computational graph. This paper explores and benchmarks one of these new node types -- the Component node -- which allows nodes to be composed manually or dynamically into processes while retaining separation of concerns in a codebase for distributed development. Composition is shown to achieve a high degree of performance optimization, particularly valuable for resource-constrained systems and sensor processing pipelines, enabling distributed tasks that would not be otherwise possible in ROS 2. In this work, we briefly introduce the significance and design of node composition, then our contribution of benchmarking is provided to analyze its impact on robotic systems. Its compelling influence on performance is shown through several experiments on the latest Long Term Support (LTS) ROS 2 distribution, Humble Hawksbill.},
	urldate = {2024-05-18},
	publisher = {arXiv},
	author = {Macenski, Steve and Soragna, Alberto and Carroll, Michael and Ge, Zhenpeng},
	year = {2023},
	note = {Version Number: 1},
	keywords = {FOS: Computer and information sciences, Robotics (cs.RO)},
}

@article{macenski_robot_2022,
	title = {Robot {Operating} {System} 2: {Design}, architecture, and uses in the wild},
	volume = {7},
	issn = {2470-9476},
	shorttitle = {Robot {Operating} {System} 2},
	url = {https://www.science.org/doi/10.1126/scirobotics.abm6074},
	doi = {10.1126/scirobotics.abm6074},
	abstract = {The next chapter of the robotics revolution is well underway with the deployment of robots for a broad range of commercial use cases. Even in a myriad of applications and environments, there exists a common vocabulary of components that robots share—the need for a modular, scalable, and reliable architecture; sensing; planning; mobility; and autonomy. The Robot Operating System (ROS) was an integral part of the last chapter, demonstrably expediting robotics research with freely available components and a modular framework. However, ROS 1 was not designed with many necessary production-grade features and algorithms. ROS 2 and its related projects have been redesigned from the ground up to meet the challenges set forth by modern robotic systems in new and exploratory domains at all scales. In this Review, we highlight the philosophical and architectural changes of ROS 2 powering this new chapter in the robotics revolution. We also show through case studies the influence ROS 2 and its adoption has had on accelerating real robot systems to reliable deployment in an assortment of challenging environments.
          , 
            This Review describes ROS 2’s design, features, and performance with four case studies on land, air, sea, and even space.},
	language = {en},
	number = {66},
	urldate = {2024-05-18},
	journal = {Science Robotics},
	author = {Macenski, Steven and Foote, Tully and Gerkey, Brian and Lalancette, Chris and Woodall, William},
	month = may,
	year = {2022},
	pages = {eabm6074},
	file = {Submitted Version:C\:\\Users\\Mikael\\Zotero\\storage\\PA4QPK9J\\Macenski et al. - 2022 - Robot Operating System 2 Design, architecture, an.pdf:application/pdf},
}

@article{chen_slam_2022,
	title = {{SLAM} {Overview}: {From} {Single} {Sensor} to {Heterogeneous} {Fusion}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {{SLAM} {Overview}},
	url = {https://www.mdpi.com/2072-4292/14/23/6033},
	doi = {10.3390/rs14236033},
	abstract = {After decades of development, LIDAR and visual SLAM technology has relatively matured and been widely used in the military and civil fields. SLAM technology enables the mobile robot to have the abilities of autonomous positioning and mapping, which allows the robot to move in indoor and outdoor scenes where GPS signals are scarce. However, SLAM technology relying only on a single sensor has its limitations. For example, LIDAR SLAM is not suitable for scenes with highly dynamic or sparse features, and visual SLAM has poor robustness in low-texture or dark scenes. However, through the fusion of the two technologies, they have great potential to learn from each other. Therefore, this paper predicts that SLAM technology combining LIDAR and visual sensors, as well as various other sensors, will be the mainstream direction in the future. This paper reviews the development history of SLAM technology, deeply analyzes the hardware information of LIDAR and cameras, and presents some classical open source algorithms and datasets. According to the algorithm adopted by the fusion sensor, the traditional multi-sensor fusion methods based on uncertainty, features, and novel deep learning are introduced in detail. The excellent performance of the multi-sensor fusion method in complex scenes is summarized, and the future development of multi-sensor fusion method is prospected.},
	language = {en},
	number = {23},
	urldate = {2024-05-22},
	journal = {Remote Sensing},
	author = {Chen, Weifeng and Zhou, Chengjun and Shang, Guangtao and Wang, Xiyang and Li, Zhenxiong and Xu, Chonghui and Hu, Kai},
	month = jan,
	year = {2022},
	note = {Number: 23
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {SLAM, LIDAR SLAM, mobile robot, multi-sensor fusion, visual SLAM},
	pages = {6033},
	file = {Full Text PDF:C\:\\Users\\Mikael\\Zotero\\storage\\YCJJLBVG\\Chen et al. - 2022 - SLAM Overview From Single Sensor to Heterogeneous.pdf:application/pdf},
}

@article{placed_survey_2023,
	title = {A {Survey} on {Active} {Simultaneous} {Localization} and {Mapping}: {State} of the {Art} and {New} {Frontiers}},
	volume = {39},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1552-3098, 1941-0468},
	shorttitle = {A {Survey} on {Active} {Simultaneous} {Localization} and {Mapping}},
	url = {https://ieeexplore.ieee.org/document/10075065/},
	doi = {10.1109/TRO.2023.3248510},
	number = {3},
	urldate = {2024-05-22},
	journal = {IEEE Transactions on Robotics},
	author = {Placed, Julio A. and Strader, Jared and Carrillo, Henry and Atanasov, Nikolay and Indelman, Vadim and Carlone, Luca and Castellanos, José A.},
	month = jun,
	year = {2023},
	pages = {1686--1705},
	file = {Accepted Version:C\:\\Users\\Mikael\\Zotero\\storage\\5W7LE2VY\\Placed et al. - 2023 - A Survey on Active Simultaneous Localization and M.pdf:application/pdf},
}

@article{cadena_past_2016,
	title = {Past, {Present}, and {Future} of {Simultaneous} {Localization} and {Mapping}: {Toward} the {Robust}-{Perception} {Age}},
	volume = {32},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1552-3098, 1941-0468},
	shorttitle = {Past, {Present}, and {Future} of {Simultaneous} {Localization} and {Mapping}},
	url = {http://ieeexplore.ieee.org/document/7747236/},
	doi = {10.1109/TRO.2016.2624754},
	number = {6},
	urldate = {2024-05-22},
	journal = {IEEE Transactions on Robotics},
	author = {Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and Scaramuzza, Davide and Neira, Jose and Reid, Ian and Leonard, John J.},
	month = dec,
	year = {2016},
	pages = {1309--1332},
	file = {Full Text:C\:\\Users\\Mikael\\Zotero\\storage\\7GXYNHY3\\Cadena et al. - 2016 - Past, Present, and Future of Simultaneous Localiza.pdf:application/pdf},
}

@article{ahmed_active_2023,
	title = {Active {SLAM}: {A} {Review} {On} {Last} {Decade}},
	volume = {23},
	issn = {1424-8220},
	shorttitle = {Active {SLAM}},
	url = {http://arxiv.org/abs/2212.11654},
	doi = {10.3390/s23198097},
	abstract = {This article presents a comprehensive review of the Active Simultaneous Localization and Mapping (A-SLAM) research conducted over the past decade. It explores the formulation, applications, and methodologies employed in A-SLAM, particularly in trajectory generation and control-action selection, drawing on concepts from Information Theory (IT) and the Theory of Optimal Experimental Design (TOED). This review includes both qualitative and quantitative analyses of various approaches, deployment scenarios, configurations, path-planning methods, and utility functions within A-SLAM research. Furthermore, this article introduces a novel analysis of Active Collaborative SLAM (AC-SLAM), focusing on collaborative aspects within SLAM systems. It includes a thorough examination of collaborative parameters and approaches, supported by both qualitative and statistical assessments. This study also identifies limitations in the existing literature and suggests potential avenues for future research. This survey serves as a valuable resource for researchers seeking insights into A-SLAM methods and techniques, offering a current overview of A-SLAM formulation.},
	language = {en},
	number = {19},
	urldate = {2024-05-23},
	journal = {Sensors},
	author = {Ahmed, Muhammad Farhan and Masood, Khayyam and Fremont, Vincent and Fantoni, Isabelle},
	month = sep,
	year = {2023},
	note = {arXiv:2212.11654 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {8097},
	file = {Ahmed et al. - 2023 - Active SLAM A Review On Last Decade.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\EAEV68Y6\\Ahmed et al. - 2023 - Active SLAM A Review On Last Decade.pdf:application/pdf},
}

@misc{sousa_systematic_2022,
	title = {A {Systematic} {Literature} {Review} on {Long}-{Term} {Localization} and {Mapping} for {Mobile} {Robots}},
	url = {https://www.authorea.com/users/519443/articles/593185-a-systematic-literature-review-on-long-term-localization-and-mapping-for-mobile-robots?commit=f805f50cb8b8ed1704e8795d03df29a57d89209e},
	doi = {10.22541/au.166739295.55264285/v1},
	abstract = {Long-term operation of autonomous robots creates new challenges to the Simultaneous Localization and Mapping (SLAM). Varying conditions of the vehicle’s surroundings, such as appearance variations (lighting, daytime, weather, or seasonal) or reconﬁgurations of the environment, are a challenge for SLAM algorithms to adapt to new changes while preserving old states. When also operating for long periods and trajectory lengths, the map should readjust to environment changes but not grow indeﬁnitely, where the map size should be dependent only on the explored environment area. Long-term SLAM intends to overcome the challenges associated with lifelong autonomy and improve the robustness of autonomous systems. Although several studies review SLAM algorithms, none of them focus on lifelong autonomy. Thus, this paper presents a systematic literature review on long-term localization and mapping following the Preferred Reporting Items for Systematic reviews and Meta-Analysis (PRISMA) guidelines. The review analyzes 142 works covering appearance invariance, modeling the environment dynamics, map size management, multi-session, and computational issues including parallel computing and timming eﬃciency. The analysis also focus on the experimental data and evaluation metrics commonly used to assess long-term autonomy. Moreover, an overview over the bibliographic data of the 142 records provides analysis in terms of keywords and authorship co-occurrence to identify the terms more used in long-term SLAM and research networks between authors, respectively. Future studies can update this paper thanks to the systematic methodology presented in the review and the public GitHub repository with all the documentation and scripts used during the review process.},
	language = {en},
	urldate = {2024-05-23},
	author = {Sousa, Ricardo B. and Sobreira, Héber M. and Moreira, Antonio},
	month = nov,
	year = {2022},
	file = {Sousa et al. - 2022 - A Systematic Literature Review on Long-Term Locali.pdf:C\:\\Users\\Mikael\\Zotero\\storage\\D5QINL22\\Sousa et al. - 2022 - A Systematic Literature Review on Long-Term Locali.pdf:application/pdf},
}

@incollection{fritsche_fusing_2018,
	address = {Cham},
	title = {Fusing {LiDAR} and {Radar} {Data} to {Perform} {SLAM} in {Harsh} {Environments}},
	isbn = {978-3-319-55011-4},
	url = {https://doi.org/10.1007/978-3-319-55011-4_9},
	abstract = {LiDAR sensors are very popular for mapping and localisation with mobile robots, yet they cannot handle harsh environments, containing smoke, fog, dust, etc. On the other hand, radar sensors can overcome these situations, but they are not able to represent an environment in the same quality as a LiDAR due to their limited range and angular resolution. In the following article, we present further results regarding SLAM involving the mechanical pivoting radar (MPR), which is a 2D high bandwidth radar scanner that was introduced in Fritsche et al. (Radar and LiDAR sensor fusion in low visibility environments, 2016, [8]). We present two strategies for fusing MPR and LiDAR data to achieve SLAM in an environment with low visibility. The first approach is based on features and requires the presence of landmarks, which can be extracted with LiDAR and MPR. The second SLAM approach is based on scan registration and requires a scan fusion between the two sensors. In the end, we show our experiments, involving real fog, in order to demonstrate, how our approaches make SLAM possible in harsh environments.},
	language = {en},
	urldate = {2024-05-26},
	booktitle = {Informatics in {Control}, {Automation} and {Robotics} : 13th {International} {Conference}, {ICINCO} 2016 {Lisbon}, {Portugal}, 29-31 {July}, 2016},
	publisher = {Springer International Publishing},
	author = {Fritsche, Paul and Kueppers, Simon and Briese, Gunnar and Wagner, Bernardo},
	editor = {Madani, Kurosh and Peaucelle, Dimitri and Gusikhin, Oleg},
	year = {2018},
	doi = {10.1007/978-3-319-55011-4_9},
	pages = {175--189},
}
